{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSE ST451: Bayesian Machine Learning\n",
    "## Author: Kostas Kalogeropoulos\n",
    "\n",
    "## Week 1: Bayesian Inference Concepts\n",
    "\n",
    "Topics covered\n",
    "\n",
    " - Introduction to Python, e.g.working with arrays, basic operation and plotting\n",
    " - Pseudo-Random numbers\n",
    " - Bayesian Inference (Point and Interval Estimation, Forecasting) with Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic operations in Python\n",
    "\n",
    "In this first session we cover basic math operations. \n",
    "\n",
    "We start with an example of basic arithmetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=3\n",
    "b=2*a\n",
    "print(b)\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will load the library **NumPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and see how we can handle 1d arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 1, 2, 3])\n",
    "print(a,a.ndim, a.shape, len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and 2d arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "print(b,b.ndim, b.shape, len(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue with some standard commands to create arrays and perform operations on them. The command linspace(start,stop,N), returns N evenly spaced values in the interval [start, stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 3, 20)\n",
    "y = np.linspace(0, 9, 20)\n",
    "print('x',x)\n",
    "print('y',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some commands to access 1d array elements and compute sums and averages on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0], y[2], y[-1], y[y>7], y[0:3], np.mean(y), np.sum(y[y>8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some commands to create 2d arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.diag(np.array([1, 2, 3, 4]))\n",
    "print('a',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Some operations to access 2d array elements and compute sums and averages on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0,0], a[2,1], a[3,3], a[2], a[:,1], a[a>2], np.sum(a), np.mean(a[3]), np.sum(a[a>1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo - random numbers\n",
    "\n",
    "Define a sequence $\\{s_i\\}$ and set (for some $a,b,s_0,M$)\n",
    "$$\n",
    "s_{i+1}=(a\\; s_i \\;+ \\;b)  \\text{mod} M.\n",
    "$$\n",
    "\n",
    "Then $U_i =\\frac{s_i}{M} \\;\\sim\\;$ Uniform$(0,1)$.\n",
    "\n",
    " For large $M$, the numbers obtained by the algorithm above satisfy all the properties of random samples from a Uniform$(0,1)$ distribution. They are called pseudo-random numbers.\n",
    "\n",
    " Given pseudo-random numbers from Uniform($0,1$) we can simulate from other known distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(4)       # Uniform(0, 1)\n",
    "print('4 uniform random numbers',a)\n",
    "b = np.random.randn(10)      # Normal(0,1)\n",
    "print('10 normal random numbers',b)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you all take different numbers. Also if you repeat you will get another set of numbers.\n",
    "\n",
    "Invdividually, everything seems to be different but collectively there is something common in all these numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Inference with Monte Carlo \n",
    "\n",
    "We will draw 100 points from a Uniform Distribution and use the **sample*** mean, variance, std and median to calculate their population counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "x = np.random.rand(n)\n",
    "print('mean',np.mean(x),np.sum(x)/n)\n",
    "print('variance',np.var(x),np.mean(x**2)-np.mean(x)**2)\n",
    "print('standard deviation',np.std(x))\n",
    "print('median',np.median(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculations seem to be in the right direction but there is Monte Carlo error. This can be reduced to arbitrarily small level by simply drawing more random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100000\n",
    "x = np.random.rand(n)\n",
    "print('mean',np.mean(x),np.sum(x)/n)\n",
    "print('variance',np.var(x),np.mean(x**2)-np.mean(x)**2)\n",
    "print('standard deviation',np.std(x))\n",
    "print('median',np.median(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way did you know the variance of Uniform[0,1] distribution? \n",
    "\n",
    "If you did well done!\n",
    "\n",
    "If not, don't worry you can always find it with Monte Carlo :)\n",
    "\n",
    "You can also find percentiles, minimums and maximums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10000\n",
    "x = np.random.rand(n)\n",
    "print('min and max',np.min(x),np.max(x))\n",
    "x = np.random.randn(n)\n",
    "print('95% credible intervals',np.percentile(x,(2.5,97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you all want to get the same results or if you want to make sure you get the same results each time you can fix the randon seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)  \n",
    "np.random.randn(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting in Python with MatPlotLib\n",
    "\n",
    "Finally time for some plotting. We start with scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "x = np.linspace(0,1,n)\n",
    "y = 2-3*x\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)\n",
    "plt.plot(x, y,'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and continute with histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=400\n",
    "y = np.random.randn(n) \n",
    "plt.hist(y,density=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density estimation\n",
    "\n",
    "Estimation of a pdf using a Kernel density estimator Draw a sample of n number of observations \n",
    "from a density f, and call the sample y. (Plot a histogram of y). Use a KDE on the sample y.\n",
    "Obtain the actual density, f. Plot actual and estimated pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import gamma\n",
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=400\n",
    "y = np.random.randn(n) \n",
    "estf = stats.gaussian_kde(y)\n",
    "x = np.linspace(-4,4,n)\n",
    "f = norm.pdf(x)\n",
    "plt.hist(y,density=1)                   #histogram of sample\n",
    "plt.plot(x,estf(x),label='KDE')         #Kerned Density Estimate\n",
    "plt.plot(x,f,color='r',label='True Density')  #Density of Normal distribution \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activities\n",
    "\n",
    "Now let's put it all together with some activities relevant to Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity 1\n",
    "\n",
    "Assume that the posterior of the variable of interest $\\theta$, $\\pi(\\theta|y)$ is the Gamma($2,1$) distribution. Provide the answers to the below using Monte Carlo. Verify by contrasting with the exact answers where possible.\n",
    "\n",
    "- Provide the Bayes estimate for $\\theta$.\n",
    "- Give a 95\\% credible interval for $\\theta$.\n",
    "- Calculate the posterior variance, $E[\\theta^3|y]$ and $P(\\theta>3|y)$.\n",
    "- Give a kernel density plot for its pdf. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity 2\n",
    "\n",
    "Assume that the posterior of the variable of interest $\\theta$, $\\pi(\\theta|y)$ is the Beta($2,7$) distribution. Provide the answers to the below using Monte Carlo. Verify by contrasting with the exact answers where possible.\n",
    "\n",
    "- Provide the Bayes estimate for $\\theta$.\n",
    "- Give a 95\\% credible interval for $\\theta$.\n",
    "- Calculate the posterior variance, $E[1/\\theta|y]$ and $P(\\theta<0.2|y)$.\n",
    "- Give a kernel density plot for its pdf. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity 3 - Bank Casheiers stuff\n",
    "\n",
    "A bank manager wants to decide on whether she should employ additional staff in the cashiers of their branch. This is usually determined by the number of customers visiting their branch on an average day.\n",
    "\n",
    "**Sample:** An experiment is conducted and the number of customers visiting the branch is recorded on $20$ random days and are shown below:\n",
    "\n",
    "$103, 115,  94, 102, 108, 108,  92, 113, 109,  89,$\n",
    "\n",
    "$96, 106, 118, 104, 116, 106, 104, 100,  98, 114$.\n",
    "\n",
    "1. Split the data into a training set (first 10 observations) and a test set (remaining observations).\n",
    "2. Assign a Poisson model to the training set and use it to obtain point forecasts for the test set. Use both Frequentist and Bayesian inference and compare their performance.\n",
    "3. Repeat the previous step but with 95\\% prediction intervals rather than point forecasts. \n",
    "4. For the frequentist approach one can estimate the Poisson parameter $\\lambda$ via the MLE, $\\hat{\\lambda}$ which is the sample mean (of the training data), . The distribution for the future data can then be the Poisson($\\hat{\\lambda}$).\n",
    "5. Since there is no prior information, the Gamma($0.001,0.001$) can be used as prior. See lecture slides for the posterior.\n",
    "6. The Mean Squared Error can be used to assess the forecasts. For the prediction intervals we can just count the number of test data contained in them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
